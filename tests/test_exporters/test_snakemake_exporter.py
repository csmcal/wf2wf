"""Tests for the Snakemake exporter functionality."""

from wf2wf.core import Workflow, Task, ResourceSpec, EnvironmentSpec
from wf2wf.exporters.snakemake import from_workflow
import os


class TestSnakemakeExporter:
    """Test the Snakemake exporter."""

    def test_export_simple_workflow(self, persistent_test_output):
        """Test exporting a simple linear workflow."""
        # Create a simple workflow
        wf = Workflow(name="simple_workflow")

        task1 = Task(
            id="prepare_data",
            command="python prepare.py input.txt output.txt",
            inputs=["input.txt"],
            outputs=["output.txt"],
            resources=ResourceSpec(cpu=2, mem_mb=4096),
        )

        task2 = Task(
            id="analyze_data",
            command="python analyze.py output.txt results.txt",
            inputs=["output.txt"],
            outputs=["results.txt"],
            resources=ResourceSpec(cpu=4, mem_mb=8192),
            environment=EnvironmentSpec(conda="envs/analysis.yaml"),
        )

        wf.add_task(task1)
        wf.add_task(task2)
        wf.add_edge("prepare_data", "analyze_data")

        # Export to Snakemake
        output_file = persistent_test_output / "simple_workflow.smk"
        from_workflow(wf, output_file, verbose=True)

        # Check that file was created
        assert output_file.exists()

        # Read and verify content
        content = output_file.read_text()

        # Check header
        assert "# Snakefile generated by wf2wf" in content
        assert "simple_workflow" in content

        # Check rules
        assert "rule all:" in content
        assert "rule prepare_data:" in content
        assert "rule analyze_data:" in content

        # Check inputs/outputs
        assert 'input: "input.txt"' in content
        assert 'output: "output.txt"' in content
        assert 'output: "results.txt"' in content

        # Check resources
        assert "cpus=2" in content
        assert "mem_gb=4" in content
        assert "cpus=4" in content
        assert "mem_gb=8" in content

        # Check conda environment
        assert 'conda: "envs/analysis.yaml"' in content

        # Check commands
        assert "python prepare.py input.txt output.txt" in content
        assert "python analyze.py output.txt results.txt" in content

    def test_export_with_config(self, persistent_test_output):
        """Test exporting workflow with configuration."""
        wf = Workflow(
            name="config_workflow",
            config={
                "analysis_params": {"threshold": 0.05, "iterations": 1000},
                "data_source": "/path/to/data",
            },
        )

        task = Task(
            id="analyze",
            command="python analyze.py --threshold {config[analysis_params][threshold]}",
            inputs=["data.txt"],
            outputs=["results.txt"],
        )
        wf.add_task(task)

        # Export with embedded config
        output_file = persistent_test_output / "config_workflow.smk"
        from_workflow(wf, output_file)

        content = output_file.read_text()

        # Check config is embedded
        assert "config = {" in content
        assert '"analysis_params"' in content
        assert '"threshold": 0.05' in content
        assert '"iterations": 1000' in content
        assert "data_source" in content and "/path/to/data" in content

    def test_export_with_separate_config(self, persistent_test_output):
        """Test exporting workflow with separate config file."""
        wf = Workflow(
            name="separate_config_workflow", config={"param1": "value1", "param2": 42}
        )

        task = Task(id="test_task", command="echo test")
        wf.add_task(task)

        # Export with separate config file
        output_file = persistent_test_output / "separate_config.smk"
        config_file = persistent_test_output / "config.yaml"

        from_workflow(wf, output_file, config_file=config_file)

        # Check Snakefile references config
        snakefile_content = output_file.read_text()
        assert 'configfile: "config.yaml"' in snakefile_content

        # Check config file was created
        assert config_file.exists()
        config_content = config_file.read_text()
        assert "param1: value1" in config_content
        assert "param2: 42" in config_content

    def test_export_with_containers(self, persistent_test_output):
        """Test exporting workflow with container specifications."""
        wf = Workflow(name="container_workflow")

        # Task with Docker container
        docker_task = Task(
            id="docker_task",
            command="python script.py",
            environment=EnvironmentSpec(container="docker://python:3.9-slim"),
        )

        # Task with direct container reference
        container_task = Task(
            id="container_task",
            command="R script.R",
            environment=EnvironmentSpec(container="bioconductor/release_core2"),
        )

        wf.add_task(docker_task)
        wf.add_task(container_task)

        output_file = persistent_test_output / "container_workflow.smk"
        from_workflow(wf, output_file)

        content = output_file.read_text()

        # Check container specifications
        assert 'container: "python:3.9-slim"' in content  # Docker prefix removed
        assert 'container: "bioconductor/release_core2"' in content

    def test_export_with_resources(self, persistent_test_output):
        """Test exporting workflow with comprehensive resource specifications."""
        wf = Workflow(name="resource_workflow")

        task = Task(
            id="resource_intensive_task",
            command="python compute.py",
            resources=ResourceSpec(
                cpu=16,
                mem_mb=32768,  # 32GB
                disk_mb=102400,  # 100GB
                gpu=2,
                time_s=7200,  # 2 hours
                threads=8,
                extra={"partition": "gpu", "account": "research"},
            ),
        )
        wf.add_task(task)

        output_file = persistent_test_output / "resource_workflow.smk"
        from_workflow(wf, output_file)

        content = output_file.read_text()

        # Check resource conversion
        assert "cpus=16" in content
        assert "mem_gb=32" in content  # Converted to GB
        assert "disk_gb=100" in content  # Converted to GB
        assert "gpu=2" in content
        assert "runtime=120" in content  # 2 hours in minutes
        assert "threads=8" in content
        assert "partition=" in content and "gpu" in content
        assert "account=" in content and "research" in content

    def test_export_with_retry_priority(self, persistent_test_output):
        """Test exporting workflow with retry and priority settings."""
        wf = Workflow(name="retry_priority_workflow")

        task1 = Task(
            id="high_priority_task", command="python important.py", priority=10, retry=3
        )

        task2 = Task(
            id="low_priority_task", command="python cleanup.py", priority=-5, retry=1
        )

        wf.add_task(task1)
        wf.add_task(task2)

        output_file = persistent_test_output / "retry_priority.smk"
        from_workflow(wf, output_file)

        content = output_file.read_text()

        # Check priority and retries
        assert "priority: 10" in content
        assert "retries: 3" in content
        assert "priority: -5" in content
        assert "retries: 1" in content

    def test_export_with_scripts(self, persistent_test_output):
        """Test exporting workflow with script references."""
        wf = Workflow(name="script_workflow")

        task_with_script = Task(
            id="script_task",
            script="scripts/analysis.py",
            inputs=["data.txt"],
            outputs=["results.txt"],
        )

        task_with_command = Task(
            id="command_task", command="echo 'Hello World'", outputs=["hello.txt"]
        )

        wf.add_task(task_with_script)
        wf.add_task(task_with_command)

        output_file = persistent_test_output / "script_workflow.smk"
        from_workflow(wf, output_file, script_dir="scripts")

        content = output_file.read_text()

        # Check script directive
        assert 'script: "scripts/analysis.py"' in content

        # Check shell command
        assert "shell: \"echo 'Hello World'\"" in content

    def test_topological_ordering(self, persistent_test_output):
        """Test that tasks are exported in topological order."""
        wf = Workflow(name="topo_workflow")

        # Create tasks in non-topological order
        task_c = Task(
            id="task_c", command="echo C", inputs=["b.txt"], outputs=["c.txt"]
        )
        task_a = Task(id="task_a", command="echo A", outputs=["a.txt"])
        task_b = Task(
            id="task_b", command="echo B", inputs=["a.txt"], outputs=["b.txt"]
        )

        # Add in random order
        wf.add_task(task_c)
        wf.add_task(task_a)
        wf.add_task(task_b)

        # Add dependencies
        wf.add_edge("task_a", "task_b")
        wf.add_edge("task_b", "task_c")

        output_file = persistent_test_output / "topo_workflow.smk"
        from_workflow(wf, output_file)

        content = output_file.read_text()

        # Find positions of rule definitions
        pos_a = content.find("rule task_a:")
        pos_b = content.find("rule task_b:")
        pos_c = content.find("rule task_c:")

        # Check topological order (task_a before task_b before task_c)
        assert pos_a < pos_b < pos_c

    def test_rule_name_sanitization(self, persistent_test_output):
        """Test that invalid rule names are sanitized."""
        wf = Workflow(name="sanitize_workflow")

        # Tasks with problematic names
        task1 = Task(id="task-with-dashes", command="echo test1")
        task2 = Task(id="task.with.dots", command="echo test2")
        task3 = Task(id="123_numeric_start", command="echo test3")
        task4 = Task(id="task with spaces", command="echo test4")

        wf.add_task(task1)
        wf.add_task(task2)
        wf.add_task(task3)
        wf.add_task(task4)

        output_file = persistent_test_output / "sanitize_workflow.smk"
        from_workflow(wf, output_file)

        content = output_file.read_text()

        # Check sanitized rule names
        assert "rule task_with_dashes:" in content
        assert "rule task_with_dots:" in content
        assert "rule rule_123_numeric_start:" in content
        assert "rule task_with_spaces:" in content

    def test_complex_workflow_from_json(
        self, sample_workflow_json, persistent_test_output
    ):
        """Test exporting the sample JSON workflow to Snakemake."""
        from wf2wf.core import Workflow

        # Load the sample workflow
        wf = Workflow.load_json(sample_workflow_json)

        # Export to Snakemake
        output_file = persistent_test_output / "sample_workflow.smk"
        from_workflow(wf, output_file, verbose=True)

        assert output_file.exists()

        content = output_file.read_text()

        # Should contain all tasks from sample workflow
        assert "rule prepare_data:" in content
        assert "rule analyze:" in content
        assert "rule generate_report:" in content

        # Should have proper all rule
        assert "rule all:" in content
        assert "final_report.pdf" in content
