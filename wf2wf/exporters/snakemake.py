"""wf2wf.exporters.snakemake â€“ Workflow IR âœ Snakemake

This module converts the wf2wf intermediate representation to Snakemake workflows.

Public API:
    from_workflow(wf, out_file, **opts)   -> writes Snakefile
"""

from __future__ import annotations

import yaml
from pathlib import Path
from typing import Any, List, Optional, Union, Dict

from wf2wf.core import Workflow, Task, ParameterSpec
from wf2wf.exporters.base import BaseExporter


class SnakemakeExporter(BaseExporter):
    """Snakemake exporter using shared infrastructure."""
    
    def _get_target_format(self) -> str:
        """Get the target format name."""
        return "snakemake"
    
    def _generate_output(self, workflow: Workflow, output_path: Path, **opts: Any) -> None:
        """Generate Snakemake output."""
        config_file = opts.get("config_file")
        create_all_rule = opts.get("create_all_rule", True)
        include_resources = opts.get("include_resources", True)
        include_conda = opts.get("include_conda", True)
        include_containers = opts.get("include_containers", True)
        script_dir = opts.get("script_dir", "scripts")
        debug = opts.get("debug", False)
        target_env = self.target_environment
        
        # Analyze workflow structure
        final_outputs = _find_final_outputs(workflow)
        input_files = _find_input_files(workflow)
        
        if debug:
            print(f"DEBUG: Final outputs: {final_outputs}")
            print(f"DEBUG: Input files: {input_files}")
        
        # Generate Snakefile content
        snakefile_lines = []
        
        # Header comment
        snakefile_lines.extend([
            f"# Snakefile generated by wf2wf from workflow '{workflow.name}'",
            "# Original format: Workflow IR",
            f"# Tasks: {len(workflow.tasks)}, Dependencies: {len(workflow.edges)}",
            "",
        ])
        
        # Config handling
        config_lines = _generate_config_section(workflow, config_file, output_path)
        snakefile_lines.extend(config_lines)
        
        # All rule (if requested and we have final outputs)
        if create_all_rule and final_outputs:
            snakefile_lines.extend([
                "rule all:",
                "    input:",
            ])
            for output in sorted(final_outputs):
                snakefile_lines.append(f'        "{output}",')
            snakefile_lines.append("")
        
        # Generate rules for each task
        script_dir_path = output_path.parent / script_dir if script_dir else None
        
        for task_id in _topological_sort(workflow):
            task = workflow.tasks[task_id]
            rule_lines = _generate_rule(
                task,
                include_resources=include_resources,
                include_conda=include_conda,
                include_containers=include_containers,
                script_dir=script_dir_path,
                debug=debug,
                target_environment=target_env,
            )
            snakefile_lines.extend(rule_lines)
            snakefile_lines.append("")
        
        # Write Snakefile
        snakefile_content = "\n".join(snakefile_lines)
        self._write_file(snakefile_content, output_path)
        
        # Report hooks
        try:
            from wf2wf import report as _rpt
            _rpt.add_artefact(output_path)
            _rpt.add_action("Exported Snakemake workflow")
        except ImportError:
            pass


# Legacy function for backward compatibility
def from_workflow(wf: Workflow, out_file: Union[str, Path], **opts: Any):
    """Convert Workflow IR to Snakemake format (legacy function)."""
    exporter = SnakemakeExporter(
        interactive=opts.get("interactive", False),
        verbose=opts.get("verbose", False)
    )
    exporter.export_workflow(wf, out_file, **opts)


# Helper functions (unchanged from original implementation)
def _find_final_outputs(wf: Workflow) -> List[str]:
    """Find final outputs that have no dependents."""
    all_outputs = set()
    for task in wf.tasks.values():
        for output in task.outputs:
            if isinstance(output, ParameterSpec):
                all_outputs.add(output.id)
            else:
                all_outputs.add(str(output))
    
    # Find outputs that are not inputs to other tasks
    final_outputs = []
    for output in all_outputs:
        is_final = True
        for task in wf.tasks.values():
            for input_param in task.inputs:
                if isinstance(input_param, ParameterSpec) and input_param.id == output:
                    is_final = False
                    break
            if not is_final:
                break
        if is_final:
            final_outputs.append(output)
    
    return final_outputs


def _find_input_files(wf: Workflow) -> List[str]:
    """Find input files that are not outputs of other tasks."""
    all_inputs = set()
    for task in wf.tasks.values():
        for input_param in task.inputs:
            if isinstance(input_param, ParameterSpec):
                all_inputs.add(input_param.id)
            else:
                all_inputs.add(str(input_param))
    
    # Find inputs that are not outputs of other tasks
    input_files = []
    for input_param in all_inputs:
        is_input = True
        for task in wf.tasks.values():
            for output in task.outputs:
                if isinstance(output, ParameterSpec) and output.id == input_param:
                    is_input = False
                    break
            if not is_input:
                break
        if is_input:
            input_files.append(input_param)
    
    return input_files


def _generate_config_section(
    wf: Workflow, config_file: Optional[Path], out_path: Path
) -> List[str]:
    """Generate config section for Snakefile."""
    config_lines = []
    
    # Extract config from workflow metadata
    config_data = {}
    if wf.metadata and "config" in wf.metadata.format_specific:
        config_data = wf.metadata.format_specific["config"]
    
    if config_data:
        if config_file:
            # Write to separate config file
            config_path = out_path.parent / config_file
            with config_path.open('w') as f:
                yaml.dump(config_data, f, default_flow_style=False)
            config_lines.extend([
                "# Configuration",
                f"configfile: '{config_file}'",
                "",
            ])
        else:
            # Embed in Snakefile
            config_lines.extend([
                "# Configuration",
                "config:",
            ])
            
            def format_config_value(value, indent=1):
                if isinstance(value, dict):
                    for k, v in value.items():
                        config_lines.append(" " * (indent * 4) + f"{k}: {v}")
                elif isinstance(value, list):
                    for item in value:
                        config_lines.append(" " * (indent * 4) + f"- {item}")
                else:
                    config_lines.append(" " * (indent * 4) + f"{value}")
            
            for key, value in config_data.items():
                config_lines.append(" " * 4 + f"{key}:")
                format_config_value(value, 2)
            config_lines.append("")
    
    return config_lines


def _generate_rule(
    task: Task,
    include_resources: bool = True,
    include_conda: bool = True,
    include_containers: bool = True,
    script_dir: Optional[Path] = None,
    debug: bool = False,
    target_environment: str = "shared_filesystem",
) -> List[str]:
    """Generate a Snakemake rule for a task, using the target environment."""
    lines = []
    rule_name = _sanitize_rule_name(task.id)
    lines.append(f"rule {rule_name}:")
    
    # Inputs
    if task.inputs:
        lines.append("    input:")
        for param in task.inputs:
            if hasattr(param, 'id'):
                lines.append(f'        "{param.id}",')
            else:
                lines.append(f'        "{param}",')
    
    # Outputs
    if task.outputs:
        lines.append("    output:")
        for param in task.outputs:
            if hasattr(param, 'id'):
                lines.append(f'        "{param.id}",')
            else:
                lines.append(f'        "{param}",')
    
    # Resources
    if include_resources:
        resources = _get_task_resources_snakemake(task, target_environment)
        if resources:
            lines.append("    resources:")
            for k, v in resources.items():
                lines.append(f"        {k}={v}")
    
    # Conda environment
    if include_conda:
        conda_env = task.conda.get_value_for(target_environment)
        if conda_env:
            lines.append(f"    conda: '{conda_env}'")
    
    # Container
    if include_containers:
        container = task.container.get_value_for(target_environment)
        if container:
            lines.append(f"    container: '{container}'")
    
    # Script or shell command
    script = task.script.get_value_for(target_environment)
    command = task.command.get_value_for(target_environment)
    if script:
        lines.append(f"    script: '{script}'")
    elif command:
        lines.append(f"    shell: '{command}'")
    else:
        lines.append("    shell: 'echo No command defined'")
    
    return lines

def _get_task_resources_snakemake(task: Task, target_environment: str = "shared_filesystem") -> Dict[str, Any]:
    """Get task resources for Snakemake for the target environment."""
    resources = {}
    cpu = task.cpu.get_value_for(target_environment)
    mem_mb = task.mem_mb.get_value_for(target_environment)
    disk_mb = task.disk_mb.get_value_for(target_environment)
    threads = task.threads.get_value_for(target_environment)
    if cpu:
        resources["cpu"] = cpu
    if mem_mb:
        resources["mem_mb"] = mem_mb
    if disk_mb:
        resources["disk_mb"] = disk_mb
    if threads:
        resources["threads"] = threads
    return resources


def _sanitize_rule_name(name: str) -> str:
    """Sanitize name for Snakemake rule."""
    import re
    # Replace spaces and special characters with underscores
    sanitized = re.sub(r'[^\w\-]', '_', name)
    # Ensure it doesn't start with a number
    if sanitized and sanitized[0].isdigit():
        sanitized = f"task_{sanitized}"
    return sanitized


def _topological_sort(wf: Workflow) -> List[str]:
    """Topological sort of tasks based on dependencies."""
    # Build dependency graph
    graph = {task_id: set() for task_id in wf.tasks}
    for edge in wf.edges:
        graph[edge.parent].add(edge.child)
    
    # Kahn's algorithm
    in_degree = {task_id: 0 for task_id in wf.tasks}
    for task_id, dependents in graph.items():
        for dependent in dependents:
            in_degree[dependent] += 1
    
    queue = [task_id for task_id, degree in in_degree.items() if degree == 0]
    result = []
    
    while queue:
        task_id = queue.pop(0)
        result.append(task_id)
        
        for dependent in graph[task_id]:
            in_degree[dependent] -= 1
            if in_degree[dependent] == 0:
                queue.append(dependent)
    
    return result
